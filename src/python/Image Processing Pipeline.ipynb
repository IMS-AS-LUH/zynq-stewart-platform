{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223fb2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpynq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_LOG_LEVEL\"]=\"SILENT\"\n",
    "\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.mmio import MMIO\n",
    "from pynq.lib.video import * \n",
    "\n",
    "import PIL.Image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67054452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Copyright (c) 2017, Xilinx, Inc.\n",
    "#   SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "\n",
    "import pynq\n",
    "import pynq.lib\n",
    "import pynq.lib.video\n",
    "\n",
    "class MyOverlay(pynq.Overlay):\n",
    "    \"\"\" The Base overlay for the Pynq-Z2\n",
    "\n",
    "    This overlay is designed to interact with all of the on board peripherals\n",
    "    and external interfaces of the Pynq-Z2 board. It exposes the following\n",
    "    attributes:\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    video : pynq.lib.video.HDMIWrapper\n",
    "         HDMI input and output interfaces\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bitfile, **kwargs):\n",
    "        super().__init__(bitfile, **kwargs)\n",
    "        if self.is_loaded():\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the base Overlay\n",
    "#base = BaseOverlay(\"base.bit\")\n",
    "\n",
    "base = MyOverlay(\"/home/xilinx/work/test.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hdmi IN/OUT Modules\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hdmi_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9d874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure HDMI IN/OUT\n",
    "# Input is configure to give gray scale\n",
    "\n",
    "#test = VideoMode(1280,720, 24)\n",
    "\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_out.configure(hdmi_in.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea56bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start HDMI IN/OUT\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff932e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bcfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = hdmi_in.readframe()\n",
    "img = PIL.Image.fromarray(frame)\n",
    "img.save(\"opencv_filters.jpg\")\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(base.image_processing_pipeline.video_out_generator_0)\n",
    "video_out_gen = MMIO(0x40010000, length=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be276e25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#video_out_gen.write(0x0, 1)\n",
    "#video_out_gen.write(0x4, 2)\n",
    "#video_out_gen.write(0x8, 3)\n",
    "#video_out_gen.write(0xc, 4)\n",
    "#video_out_gen.write(0x10, 5)\n",
    "\n",
    "\n",
    "print(video_out_gen.read(0x0))\n",
    "print(video_out_gen.read(0x4))\n",
    "print(video_out_gen.read(0x8))\n",
    "print(video_out_gen.read(0xc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bab697",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_out_gen.write(0x4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032c10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Horizontal Sync\")\n",
    "offset = 0x002c\n",
    "print(base.video.hdmi_in.frontend.vtc_in.read(offset) & 0x00001FFF)\n",
    "print((base.video.hdmi_in.frontend.vtc_in.read(offset) & 0xFFFF0000) >> 16)\n",
    "\n",
    "print(\"\\n\")\n",
    "offset += 4\n",
    "print(base.video.hdmi_in.frontend.vtc_in.read(offset) & 0x00001FFF)\n",
    "print((base.video.hdmi_in.frontend.vtc_in.read(offset) & 0xFFFF0000) >> 16)\n",
    "\n",
    "print(\"\\n\")\n",
    "offset += 4\n",
    "print(base.video.hdmi_in.frontend.vtc_in.read(offset) & 0x00001FFF)\n",
    "print((base.video.hdmi_in.frontend.vtc_in.read(offset) & 0xFFFF0000) >> 16)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Vertical Sync\")\n",
    "offset += 4\n",
    "print(base.video.hdmi_in.frontend.vtc_in.read(offset) & 0x00001FFF)\n",
    "print((base.video.hdmi_in.frontend.vtc_in.read(offset) & 0xFFFF0000) >> 16)\n",
    "\n",
    "print(\"\\n\")\n",
    "offset += 4\n",
    "print(base.video.hdmi_in.frontend.vtc_in.read(offset) & 0x00001FFF)\n",
    "print((base.video.hdmi_in.frontend.vtc_in.read(offset) & 0xFFFF0000) >> 16)\n",
    "\n",
    "print(\"\\n\")\n",
    "offset += 4\n",
    "print(base.video.hdmi_in.frontend.vtc_in.read(offset) & 0x00001FFF)\n",
    "print((base.video.hdmi_in.frontend.vtc_in.read(offset) & 0xFFFF0000) >> 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussion approximation. Could easily be implemented as shifts\n",
    "kernel_smoothing_values = np.array(\n",
    "    [ \n",
    "        [ 1,  4,  6,  4, 1],\n",
    "        [ 4, 16, 24, 16, 4],\n",
    "        [ 6, 24, 36, 24, 6],\n",
    "        [ 4, 16, 24, 16, 4],\n",
    "        [ 1,  4,  6,  4, 1],\n",
    "    ])\n",
    "kernel_smoothing = (1/256) * kernel_smoothing_values \n",
    "\n",
    "print (kernel_smoothing)\n",
    "\n",
    "# Smoothes frame_in\n",
    "def image_smoothing(frame_in):\n",
    "    \"\"\"\n",
    "        Smoothes frame_in with a 5x5 Gaussion Approximation Filter\n",
    "    \"\"\"\n",
    "    result = cv2.filter2D(frame_in, cv2.CV_8U, kernel_smoothing)\n",
    "    result = cv2.boxFilter(frame_in, cv2.CV_8U, [3, 3])\n",
    "    display(PIL.Image.fromarray(result))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative Filter Kernels\n",
    "kernel_edge_x = np.array([[1, 0, -1]])\n",
    "kernel_edge_y = np.transpose(kernel_edge_x)\n",
    "\n",
    "#print(kernel_edge_x)\n",
    "#print(kernel_edge_y)\n",
    "\n",
    "\n",
    "def edge_detection(frame_in):\n",
    "    \"\"\"\n",
    "        Calculates the gradient in x and y direction with a normal derivative filter Kernel. Both\n",
    "        the x and y derivative are returned.\n",
    "    \"\"\"\n",
    "    gradient_x = cv2.filter2D(frame_in, cv2.CV_16S, kernel_edge_x)\n",
    "    gradient_y = cv2.filter2D(frame_in, cv2.CV_16S, kernel_edge_y)\n",
    "    \n",
    "    #display(PIL.Image.fromarray(np.abs(gradient_x)))\n",
    "    #display(PIL.Image.fromarray(np.abs(gradient_y)))\n",
    "    \n",
    "    return (gradient_x, gradient_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(gradient_x, gradient_y):\n",
    "    \"\"\"\n",
    "        Takes the x and y gradient and calculates \"true\" edges. Uses canny edge detector.\n",
    "    \"\"\"\n",
    "\n",
    "    threshold1 = 1\n",
    "    threshold2 = 20\n",
    "    \n",
    "    # Compute the magnitude and direction of the gradient\n",
    "    magnitude = np.hypot(gradient_x, gradient_y)\n",
    "    #magnitude = np.abs(gradient_x) + np.abs(gradient_y)\n",
    "    direction = np.arctan2(gradient_y, gradient_x) * 180/np.pi\n",
    "\n",
    "    display(PIL.Image.fromarray(magnitude.astype(np.uint8)))\n",
    "    \n",
    "    # Perform non-maximum suppression to thin the edges\n",
    "    \n",
    "    \n",
    "    M, N = magnitude.shape\n",
    "    thin_edges = np.zeros((M, N), dtype=np.uint8)\n",
    "    edge_rows, edge_cols = np.where(magnitude > 0)\n",
    "    \n",
    "    norm = 255 / np.max(magnitude)\n",
    "    \n",
    "    print(M,N, len(edge_rows), norm, np.max(magnitude))\n",
    "    for index in range(1, len(edge_rows) - 2):\n",
    "        #print(\"\\r\", i, end='')\n",
    "       \n",
    "        try:\n",
    "            i = edge_rows[index]\n",
    "            j = edge_cols[index]\n",
    "\n",
    "            q = 255\n",
    "            r = 255\n",
    "\n",
    "           #angle 0\n",
    "            if (0 <= np.abs(direction[i,j]) < 22.5) or (157.5 <= np.abs(direction[i,j]) <= 180):\n",
    "                q = magnitude[i, j+1]\n",
    "                r = magnitude[i, j-1]\n",
    "            #angle 45\n",
    "            elif (22.5 <= np.abs(direction[i,j]) < 67.5):\n",
    "                q = magnitude[i+1, j-1]\n",
    "                r = magnitude[i-1, j+1]\n",
    "            #angle 90\n",
    "            elif (67.5 <= np.abs(direction[i,j]) < 112.5):\n",
    "                q = magnitude[i+1, j]\n",
    "                r = magnitude[i-1, j]\n",
    "            #angle 135\n",
    "            elif (112.5 <= np.abs(direction[i,j]) < 157.5):\n",
    "                q = magnitude[i-1, j-1]\n",
    "                r = magnitude[i+1, j+1]\n",
    "\n",
    "            if (magnitude[i,j] >= q) and (magnitude[i,j] >= r):\n",
    "                thin_edges[i,j] = magnitude[i,j] * norm\n",
    "            else:\n",
    "                thin_edges[i,j] = 0\n",
    "        except IndexError as e:\n",
    "            pass\n",
    "            \n",
    "    \n",
    "    print(\"Thin Edges\")\n",
    "    display(PIL.Image.fromarray(thin_edges))\n",
    "    \n",
    "    print(\"Hysteresis\")\n",
    "    # Perform hysteresis thresholding to segment the edges\n",
    "    weak = 75\n",
    "    strong = 255\n",
    "    strong_rows, strong_cols = np.where(thin_edges >= threshold2)\n",
    "    weak_rows, weak_cols = np.where((thin_edges <= threshold2) & (thin_edges >= threshold1))\n",
    "\n",
    "    # Set strong edges to white\n",
    "    edges = np.zeros_like(thin_edges)\n",
    "    edges[strong_rows, strong_cols] = strong\n",
    "    \n",
    "    # Check for weak edges connected to strong edges\n",
    "    for i in range(len(weak_rows)):\n",
    "        row = weak_rows[i]\n",
    "        col = weak_cols[i]\n",
    "        if (edges[row - 1:row + 2, col - 1:col + 2] == strong).any():\n",
    "            edges[row, col] = strong\n",
    "\n",
    "    result = edges        \n",
    "    \n",
    "    display(PIL.Image.fromarray(result))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(frame):\n",
    "    \"\"\"\n",
    "        Calculates the hough trasform.\n",
    "        Currently not fully implemented as the HoughCircles function really slow is. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Todo Implement\n",
    "    \n",
    "    result = cv2.HoughCircles(frame, cv2.HOUGH_GRADIENT, 1, 1)\n",
    "    \n",
    "    #print(result)\n",
    "    #display(PIL.Image.fromarray(result))\n",
    "    \n",
    "    for i in range(0, len(result[0])):\n",
    "        center = (int(result[0][i][0]), int(result[0][i][1]))\n",
    "        cv2.circle(frame, center, int(result[0][i][2]), (255, 0, 255))\n",
    "    \n",
    "    display(PIL.Image.fromarray(frame))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(hough_space):\n",
    "    \"\"\"\n",
    "        Detect circles in the HoughSpace.\n",
    "        Not Implemented\n",
    "    \"\"\"\n",
    "    # Todo Implement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701cfef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Reading a frame and than handing it to the processing functions.\n",
    "# Partial Images are displayed during processing from within the functions.\n",
    "#\n",
    "\n",
    "frame =  hdmi_in.readframe()\n",
    "\n",
    "width, height = frame.shape\n",
    "print(width, height)\n",
    "small_frame = frame[540:1080, 400:960]\n",
    "display(PIL.Image.fromarray(small_frame))\n",
    "\n",
    "smooth = image_smoothing(small_frame)\n",
    "gradients = edge_detection(smooth)\n",
    "edges = canny(gradients[0], gradients[1])\n",
    "hough = hough_transform(frame);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e2fc1",
   "metadata": {},
   "source": [
    "# Pass Through Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fc93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseOverlay(\"base.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ed393",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdmi_in.configure()\n",
    "hdmi_out.configure(hdmi_in.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.tie(hdmi_out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.stop()\n",
    "hdmi_out.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27907702",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(VideoMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1504c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18439cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
